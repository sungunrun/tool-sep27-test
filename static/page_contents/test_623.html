<div id="PGHEADER">
Relations Among Types of Visual Perceptual Memory 623</div>
<br><br>
can be drummed into innate architecture. Learning can modify innate defaults or cause <br>
representation of new co-occurrence tendencies. Having prior information about co-<br>
occurrence enables memory to use fewer resources in retaining new representational <br>
 contents and in facilitating recognition and retrieval.<br>
<br>
The study of memory tracks structures among different types of retained attributives—<br>
perceptual and conceptual, kind-determining attributives, and property and relation <br>
attributives. Chunking has a fine-structure. Some types provide more benefits for storage <br>
and retrieval than others. Work that investigates how memory storage depends on the <br>
content and structure of what is stored is an active part of memory research.974<br>
<br>
For example, perceptual memory’s representation of objects is often not as full as <br>
 perception’s representation of them. If an object’s property is not task-relevant, it may be <br>
forgotten, or at least not readily accessible to consciousness. If object properties do not <br>
characterize whole objects (for example, different parts of the object have different colors), <br>
encoding the properties and chunking are more difficult.975<br>
<br>
Relations between conceptual and perceptual attributives in visual long-term memory, <br>
(VLTM), are complex. Verbal labeling of a category of items (<i>wristwatch</i>) can overmatch <br>
perceptual encoding of more specific, even differentiating, properties to produce false rec-<br>
ognition responses. The label can lead a memory system to focus on similarities between <br>
previously perceived and currently perceived items and to distract from different percep-<br>
tual features in the different displays. So a subject reports that a currently displayed item <br>
has been seen before, whereas only an instance of perceptual correlate (a different watch-<br>
body type) that is thought under the same conceptual category (wristwatch) had been <br>
seen.976 As in CSTM, so in VLTM, verbal and template-based perceptual primings nor-<br>
mally work together to make search more efficient and to make perceptual recognition <br>
quicker and more accurate.977<br>
<br>
These examples emphasize that the form and type of representational content in visual <br>
working memory, CSTM, and VLTM affect operations of storage, retrieval, and recogni-<br>
tion. It would be a mistake, however, to regard vision as hopelessly trumped, much less <br>
hopelessly biased, by memory. Most memory-induced patterns of error are taken by scien-<br>
tists to result from patterns that, in the long-run, benefit both survival and accuracy.<br><br>
<div id='SUBSECTITLE'>
<b>Summary of Relations Among Major Types of Visual Perceptual Memory<br><br>
</div>
</b>I conclude these two chapters on visual perceptual memory with an overview of the main <br>
relations among the different types. Visual perception normally provides detailed <br><br>

<div id= 'FOOTNOTES'>
<b>FOOTNOTES</b><br>
<b>FN</b>974 These points have been emphasized by the George Alvarez lab. See, for example, Brady, Konkle, and <br>
Alvarez, ‘A Review of Visual Memory Capacity: Beyond Individual Items and Toward Structured Representations’.<br>
<br>
<b>FN</b>975 Y. Xu, ‘Encoding Color and Shape from Different Parts of an Object in Visual Short-Term Memory’, <br>
<i>Perception and Psychophysics</i> 64 (2002), 1260–1280; J. Droll, M. Hayhoe, J. Triesch, and B. Sullivan, ‘Task Demands <br>
Control Acquisition and Storage of Visual Information’, <i>Journal of Experimental Psychology: Human Perception <br>
and Performance</i> 31 (2005), 1416–1438.<br>
<br>
<b>FN</b>976 W. Koutstaal, C. Reddy, E. Jackson, S. Prince, D. Cendan, and D. Schacter, ‘False Recognition of Abstract <br>
Versus Common Objects in Older and Younger Adults: Testing the Semantic Categorization Account’, <i>Journal of <br>
Experimental Psychology: Learning, Memory and Cognition</i> 29 (2003), 499–510.<br>
<br>
<b>FN</b>977 Bravo and Farid, ‘The Specificity of the Search Template’; J. Wolfe, M. Vo, K. Evans, and M. Greene, ‘Visual <br>
Search in Scenes Involves Selective and Nonselective Pathways’, <i>Trends in Cognitive Sciences</i> 15 (2011), 77–84; <br>
Bravo and Farid, ‘Task Demands Determine the Specificity of the Search Template’.</div>

