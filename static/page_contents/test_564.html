<div id="PGHEADER">
564 Perceptual Attention</div>
<br><br>
propositional-level antecedents. All such antecedent drivers connect to the perceptual sys-<br>
tem via perceptual-level capacities. Attention commands, like motor commands, cited by <br>
the computational explanations have perceptual-level contents.<br>
<br>
The model of conation discussed in Chapter 14 reapplies here. Like propositional <br>
intentions, propositional-level attention commands that guide visual and motor changes <br>
operate through perceptual-level intermediaries. A propositional-level intention’s guid-<br>
ing action involving body movement and a propositional attention command’s selecting <br>
a <i>representatum</i> for attentional enhancement, or causing a saccade, operate through <br>
target-setting-, motor-, attention-, or saccade-commands at the perceptual level. A prop-<br>
os ition al initiation of attention selects <i>representata</i> for attentional focus. The focus is <br>
channeled representationally to visual perception. Some attention initiation specifies <br>
<i>representata</i> in a way that selects perceptual capacities for attention-boosted represent-<br>
ing. At some stage in the causal chain, a state with attentional impetus must select the <br>
perceptual capacities to be enhanced. Relevant perceptual capacities just are perceptual <br>
attributives. The most natural, computationally simplest form of selection specifies the <br>
<i>representata</i> in ways that perceptual states specify them. The state with selectional <br>
im petus is an attention command with the iconic perceptual attributives as content: <br>
such attributives represent the foci (area, feature, or object) selected for attention within <br>
a visual perceptual state. So the representational command that directly channels atten-<br>
tion to a perceptual state in effect selects perceptual capacities—perceptual attribu-<br>
tives—that specify the relevant <i>representata</i>. So the command is a perceptual-level <br>
attention command. Computational explanations of the visuomotor system assume <br>
homogeny of content, of representational capacities, in computations. So natural com-<br>
putational explanations take propositional antecedents of attention and conation to <br>
affect visual perception through representational states at the representational level of <br>
perception. Even individually controlled shifts in attention and saccades that are guided <br>
propositionally normally operate through perceptual-level attention commands and <br>
perceptual-level saccadic commands.<br>
<br>
Again, actual explanations in the science support the point. Computational models of <br>
attention-shifts and saccades, as we have seen, do not invoke supra-perceptual-level states <br>
even in cases in which such attitudes drive attention or eye movement. Computational <br>
models operate at the perceptual level or below. Where representational resources are <br>
boosted by attention, and there is a computational, representation-invoking explanation <br>
of endogenous attention, the models do not, and need not, appeal to supra-perceptual-<br>
level causal antecedents. Representational causal initiators of attention—attention com-<br>
mands—in the models are content-typed by the perceptual capacities that are boosted. <br>
The types are those of the capacities (for example, perceptual attributives for spatial area <br>
or for features) that are enhanced through attention boosts. Attention itself is the winning-<br>
of-a-competition by those capacities. Representational initiations of attention specify <br>
objects of attention using those types of capacities.<br>
<br>
There is not the slightest evidence that computational psychophysical explanations <br>
appeal to propositional or other supra-perceptual-level states. They specify selection and <br>
what is selected (where the attention goes) in terms of the kinds of representational cap aci-<br>
ties that are attention-enhanced. Representationally individuated initiations of en dogen ous <br>
attention into visual processing always have content and format shared with perceptual <br>
states. These perceptual-level causes of endogenous attention ground computational </div>

