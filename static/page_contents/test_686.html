<div id="PGHEADER">
686 Perception and Cognition</div>
<br><br>
What is clear from Pylyshyn’s remarks on penetration is, minimally, that the causal rela-<br>
tions must be mental and capable of grounding law-like explanations of well-functioning <br>
psychological processes in terms of contentful transitions.1124<br>
<br>
Fodor writes:<br><br>
Imagine a computational system with a proprietary (e.g. Chomskian) database. Imagine <br>
<br>
that this device operates to map its characteristic inputs onto its characteristic outputs (in <br>
<br>
effect, to compute a function from the one to the other) and that, in the course of doing <br>
<br>
so, its informational resources are restricted to what its proprietary database contains. <br>
<br>
That is, the system is “encapsulated” with respect to information that is <i>not</i> in its database. <br>
<br>
(This might be for either, or both, of the kinds of reasons considered above. Its operations <br>
<br>
are defined with less than full generality or its informational exchanges with other pro-<br>
<br>
cessing mechanisms are constrained.) That’s what I mean by a module. It’s informational <br>
<br>
encapsulation, however achieved, that’s at the heart of modularity.1125<br><br>
Here, Fodor mentions two ways in which a computational system can be encapsulated. <br>
Each can be for-the-most-part or absolute. One way is for there to be constraints on infor-<br>
mation exchanges with other processing mechanisms. I take this way to limit (or in an <br>
absolutely encapsulated system, to block) causal content-based exchanges with other pro-<br>
cessing mechanisms. I think it fair to assume that Fodor, like Pylyshyn, would have <br>
required such exchanges to be law-like and non-pathological. The other way is for there to <br>
be limits on what contentful states the computational operations operate on. Computations <br>
in an absolutely encapsulated system would operate only on states whose contents are pro-<br>
prietary to the system. This alternative would allow non-pathological contentful influence <br>
from outside the system, as long as the states or their contents are not operated upon <i>com-<br>
putationally</i>—as long as the contentful states beyond the proprietary ones do not feed into <br>
the system’s computational operations.<br>
<br>
Although Fodor separates these two ideas in the quoted passage, he runs them together, <br>
and even ignores the second idea, in most other passages. He focuses almost entirely on <br>
the first idea. His focus is on insensitivity, or lack of non-pathological access, to informa-<br>
tion from outside a module. Sometimes, his formulations actually exclude the second <br>
idea—explaining encapsulation entirely in terms of the first.1126 The idea of lack of infor-<br>
mation access has merit in defending relative encapsulation. It faces harder going in <br>
defending absolute encapsulation. I think that the second idea provides better guidance <br>
toward understanding scientific theory and practice.<br><br>

<div id= 'FOOTNOTES'>
<b>FOOTNOTES</b><br>
<b>FN</b>1124 Stokes, ‘The Cognitive Penetration of Perception’, does not include even this much restriction on <br>
cognitive-perceptual causation. He writes, ‘perceptual experience E is cognitively penetrated if and only if (1) E is <br>
causally dependent upon some cognitive state C and (2) the causal link between E and C is internal and mental’ <br>
(650). Many pathological cases fit this description. This type of account tended to divert discussion from what <br>
Pylyshyn actually proposed, often while purporting to criticize Pylyshyn.<br>
<b>FN</b>1125 J. Fodor, <i>The Mind Doesn’t Work That Way</i> (Cambridge, MA: The MIT Press, 2000), 63.<br>
<b>FN</b>1126 Thus in the very next paragraph—Fodor, <i>The Mind Doesn’t Work That Way</i>, 63–64—he focuses on a <br>
modu lar computational system’s not having access to informational resources outside its proprietary data base. <br>
In Fodor, <i>The Modularity of Mind</i>, emphasis is almost entirely on limited or lack of informational access. See, for <br>
example, 67ff‥ On p. 69, he writes: ‘…the claim that input systems are informationally encapsulated is equivalent <br>
to the claim that the data that can bear on the confirmation of perceptual hypotheses includes, in the general <br>
case, considerably less than the organism may know’. Since input can “bear on” formation of perceptual represen-<br>
tations without being operated on in perceptual computations, this statement seems to <i>exclude</i> the second idea. <br>
Later in the book, limitation of access remains the focus, see 100ff‥</div>

