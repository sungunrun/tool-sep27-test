<div id="PGHEADER">
Conceptions of Penetration 689</div>
<br><br>
utilized almost from the advent of vision science, more than a century ago. Fodor knew <br>
these facts.1131<br>
<br>
Despite Wu’s stated aim of illuminating computation, these ideas bear no obvious rela-<br>
tion to computation. The contextual translation in the telephone example between persons <br>
<i>A</i>, <i>B</i>, and <i>C</i> is very far from computation. More importantly, it does not correspond to <br>
prominent patterns of explanations in vision or visuo-motor science.<br>
<br>
I think that the idea of use <i>in</i> a computation—Fodor’s second way—is valuable in <br>
understanding actual practice in vision science. I think it more valuable than appeals to <br>
logic, rationality—much less contextual translation. Intentions and linguistic instructions <br>
do sometimes affect saccade commands. And saccade commands do sometimes use  <br>
representational contents that are, through corollary discharge, operated upon by compu-<br>
tational processes in vision. But no contents of intentions, understood as supra-perceptual-<br>
level states, are known to be input or output for computational processes in the <br>
visuo-motor system. The science does not propose, and has not been shown to need to <br>
propose, to include intentions in its computational models.<br>
<br>
The contents of intentions specifically about clothing may not figure in visual or <br>
perceptual-level motor computational processes. What of lower-level contents of <br>
propositional-level intentions? What of an intention to search a spatial position for a <br>
shape and texture? The contents of such intentions are conceptual. They are kinds of com-<br>
petencies to engage in propositional inference. Vision science and motor science do not <br>
attribute such states or competencies. The conative states that ground explanations are <br>
perceptual-level, not propositional. (See Chapter 14.) So there is no reason to think that <br>
the contents of propositional-level intentions figure in the visual or visuo-motor systems’ <br>
computations.<br>
<br>
Wu gestures at a notion of information exchange between cognitive states and non-<br>
cognitive operations in the visual and motor systems. The conception does challenge <br>
Pylyshyn’s vague remarks about what penetration is and Fodor’s suggestions of causal <br>
imperviousness to normal cognitive causes. It does not support a rethinking of relations <br>
among instances of psychological kinds—of the sort advertised by proponents of cogni-<br>
tive penetration. The facts that Wu lays out have long been recognized.<br>
<br>
Broadly similar points apply to linguistic effects on perception that derive from labeling <br>
an object or feature before a perceptual task is initiated. Potter’s experiments illustrated <br>
these effects. (See Chapter 11, the section Two Lines of Empirical Criticism of <br>
Treisman’s Theory; Chapter 16, the section Conceptual Short-Term <br>
Memory.) Labeling a picture before it is presented in a rapid sequence improves per-<br>
form ance. Labeling effects have been found for grouping of colors, for conscious object <br>
recognition, and for conscious object detection. Label priming sometimes has stronger <br>
effects than other types of priming.1132 Priming is a low-level effect. It operates through <br>
sensory associations with the label. Priming sets up perceptual anticipations that speed or <br><br>

<div id= 'FOOTNOTES'>
<b>FOOTNOTES</b><br>
<b>FN</b>1131 Fodor, <i>The Modularity of Mind</i>, 67.<br>
<br>
<b>FN</b>1132 J. Winawer, N. Witthoft, M. Frank, L. Wu, A. Wade, and L. Boroditsky, ‘Russian Blues Reveal Effects of <br>
Language on Color Discrimination’, <i>Proceedings of the National Academy of Sciences</i> 104 (2007), 7780–7785; <br>
G. Lupyan, ‘Linguistically Modulated Perception and Cognition: The Label-Feedback Hypothesis’, <i>Frontiers in <br>
Psychology</i> 3 (2012), 1–13; G. Lupyan and E. Ward, ‘Language Can Boost Otherwise Unseen Objects into Visual <br>
Awareness’, <i>Proceedings of National Academy of Science</i> 110 (2013), 14196–14203; B. Boutonnet and G. Lupyan, <br>
‘Words Jump-Start Vision: A Label Advantage to Object Recognition’, <i>Journal of Neuroscience</i> 35 (2015), <br>
9329–9335.</div>

