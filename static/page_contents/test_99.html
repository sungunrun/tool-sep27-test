<div id="PGHEADER">
visual teMporal perceptual constancies 99</div>
<br><br>
Filling in consists in various types of operation. I mention four. One is attributing more <br>
features. For example, an initial generic face-shape representation might be supplemented <br>
to produce the specifics of the eye areas, the texture of the surface, the precise dispositions <br>
of the eyes, mouth, and so on. Second, a corollary of the first, feedback produces specific <br>
groupings of spatial types and objects categorized by those specific types. For example, <br>
animal-shapes and animal-bodies are grouped into dog-shapes, dog-bodies, hound-<br>
shapes, hound-bodies. Third, reinforcement of associations between different types of <br>
attributes is produced by exchanges with memory. For example, a tendency to associate <br>
and anticipate a type of human-face configuration of features might be reinforced. Fourth, <br>
harder discriminations are carried out, and atypical settings are assimilated. For example, <br>
if an object is embedded in an especially cluttered environment with many potential dis-<br>
tractors, feedback helps a system mark the object’s boundaries in relation to background. <br>
Sketch-like initial representations give way to more detailed, more filled-in representa-<br>
tions. However, basic categorizations occur on the first wave of processing, before feedback <br>
floods the system.105<br>
<br>
Models vary in the shares that they assign to innate structures and learned structures in <br>
this process. Some of these groupings are certainly learned in individual perceivers. <br>
Grouping of dog-shapes and knife-shapes are surely learned. The learning can occur at <br>
the perceptual-level, involving no concepts or other higher-level representation. (See <br>
Chapter 18.)<br>
<br>
These are illustrative sketches of some processes that figure in forming spatial constan-<br>
cies and perceptual categorizations that use them. I add detail in Chapters 11–13.<br><br>
<div id='SUBSECTITLE'>
<b>Visual Temporal Perceptual Constancies<br><br>
</div>
</b><i>Relational</i> spatial constancies are to be distinguished from <i>property</i> spatial constancies. <br>
Relational spatial constancies include those for distance, location, ordinal depth. Property <br>
spatial constancies include those for size, length, shape. The size and shape of a particular <br>
can be determined by tracing the volume in space that it occupies. A boundary’s length <br>
can be determined by tracing the line that it corresponds to. The size and shape of a par-<br>
ticular is not the space that it occupies. They go where the body goes. The volume that <br>
comprises a set of positions in space does not move. One can perceive instances of size, <br>
shape, and length. One cannot perceive volumes of space or spatial lines.<br>
<br>
Most relational spatial and temporal constancies are <i>framework constancies</i>. (See this <br>
chapter, the section Two Misguided Ways of Thinking About Perceptual <br>
Constancies and Chapter 8.) They are constancies for a relation-magnitude or an <br>
or din al depth or duration relation attributed from an anchor for a spatial or temporal <br>
framework. The framework need not, though it sometimes does, map a large region of <br>
space or time. Relational spatial and temporal constancies are for attributes whose <br><br>

<div id= 'FOOTNOTES'>
<b>FOOTNOTES</b><br>
<b>Cont FN</b>105 T. Carlson, D. Tovar, A. Alink, and N. Kriegeskorte, ‘Representational Dynamics of Object Vision: The First <br>
1000 ms’, <i>Journal of Vision</i> 13 (2013), 1–19; D. Wyatte, D. Jilk, and R. O’Reilly, ‘Early Recurrent Feedback <br>
Facilitates Visual Object Recognition Under Challenging Conditions’, <i>Frontiers in Psychology</i> 5 (2014), 1–10; <br>
Chen, Yan, Gong, Gilbert, Liang, and Li, ‘Incremental Integration of Global Contours through Interplay between <br>
Visual Cortical Areas’; D. Kaiser, D. Azzalini, and M. Peelen, ‘Shape-Independent Object Category Responses <br>
Revealed by MEG and fMRI Decoding’, <i>Journal of Neurophysiology</i> 115 (2016), 2246–2250.</div>

