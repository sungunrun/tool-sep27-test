<div id="PGHEADER">
554 Perceptual Attention</div>
<br><br>
system that I have described does not <i>require</i> supra-perceptual-level influence. Computational <br>
accounts of these operations do not cite supra-perceptual-level causation. I discuss this <br>
situation further in Chapter 19.<br>
<br>
I turn from these reflections on neural function and timing to discussion of computa-<br>
tional modeling of saccade preparation. Computational modeling of the representational <br>
patterns of principled, automatic, unconscious shifts of attention that cause saccade <br>
 commands is among the most detailed, sophisticated, and powerful modeling in psycho-<br>
physics.793 In visual search for a target with specific visual attributes, the visual system <br>
relies on attention to areas in peripheral vision. Peripheral vision is poor, compared to <br>
foveal vision, in representing both features and location. If a search target is not foveated, <br>
attention to peripheral areas—or to features in peripheral areas—is necessary to deter-<br>
mine where the eyes should be directed to find a target. Search begins with a template of <br>
the target. The template represents key diagnostic target attributes. The search seeks to <br>
match the template by a similarity metric with a perceptual representation of a particular.<br>
<br>
Eye movements are not random. Efficient search is crucial for survival. It is not surpris-<br>
ing that visual systems evolved efficient strategies in determining fixation locations. They <br>
do not follow the intuitively plausible rule of shifting to the peripheral area of a scene that <br>
has the highest antecedent probability (given poor peripheral registration or perception) <br>
of yielding a match of the search target. Instead, they follow a rule that maximizes the <br>
probability of finding the target <i>after</i> the eye movement, in effect minimizing the length of <br>
search required to find the target. For example, there are shifts to the center of an area that <br>
is closely surrounded by three candidate targets, all of which have a fairly high probability <br>
of matching the target-template. Before a saccade command to the area, none of the three <br>
candidates has the highest probability of matching the template. To achieve a template-<br>
match, vision need not land on the target. It is enough to get close. Getting close can also <br>
suffice to rule out candidate targets as matches. The computational process follows a rule <br>
that maximizes sensory or sensory-perceptual information relevant to the target search. <br>
The rule is near ideal in finding a target in a minimum number of eye movements.<br>
<br>
Saccade commands initiate default steps in the search process. They can be overridden <br>
by conscious plans and decisions by the perceiver. In the absence of such overrides, they <br>
operate unconsciously and independently of perceiver control.<br>
<br>
The account of the rule that the eye movement commands follow requires specification <br>
of a <i>visibility map</i>. A visibility map is an essential element in the explanation. A visibility <br>
map quantifies difficulty of detecting a target or target location via different retinal areas. So <br>
peripheral areas at greater eccentricity from foveal areas are marked with higher degrees of <br>
difficulty. Since the map is fixed for the retina, it is applied to a different area of a scene with <br>
each saccade. So the degree of difficulty of perceiving a particular at a given position in a <br>
scene changes with eye movements. The relevant psychological sub-system integrates or <br>
keeps track of degree of similarity of particulars at or near each foveated position as <br><br>

<div id= 'FOOTNOTES'>
<b>FOOTNOTES</b><br>
<b>FN</b>793 What follows is mostly based on this series of articles: J. Najemnik and W. Geisler, ‘Optimal Eye Movement <br>
Strategies in Visual Search’, <i>Nature</i> 434 (2005), 387–391; J. Najemnik and W. Geisler, ‘Eye Movement Statistics in <br>
Humans are Consistent with an Optimal Search Strategy’, <i>Journal of Vision</i> 8 (2008), 1–14; J. Najemnik and <br>
W. Geisler, ‘Simple Summation Rule for Optimal Fixation Selection in Visual Search’, <i>Vision Research</i> 49 (2009), <br>
1286–1294; M. Michel and W. Geisler, ‘Intrinsic Position Uncertainty Explains Detection and Localization <br>
Performance in Peripheral Vision’, <i>Journal of Vision</i> 11 (2011), 1–18. See also M. Pomplun, E. Reingold, and <br>
J. Shen, ‘Area Activation: A Computational Model of Saccadic Selectivity in Visual Search’, <i>Cognitive Science</i> 27, <br>
(2003), 299–312; A. Torralba, A. Oliva, M. Castelhano, and J. Henderson, ‘Contextual Guidance of Attention in <br>
Natural Scenes: The Role of Global Features on Object Search’, <i>Psychological Review</i> 113 (2006), 766–786.</div>

