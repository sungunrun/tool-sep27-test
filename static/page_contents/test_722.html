<div id="PGHEADER">
722 Perception and Cognition</div>
<br><br>
So capacities come first. Insight into capacities benefits, however, from reflecting on form <br>
and function. These points are not just abstract slogans. They guide an approach to under-<br>
standing perception, and representation generally, that sharply contrasts with traditional <br>
empiricist approaches.<br>
<br>
Perception and thought are not well distinguished by taking them to differ in degree of <br>
abstractness. They differ fundamentally in their <i>basic attributional</i> structure, and their <br>
functions, capacities, and uses, not fundamentally in their format or degree of abstractness.<br><br>
<div id='SUBSECTITLE'>
<b>What Should Count as Cognition?<br><br>
</div>
</b>I assume that cognition and perceptual-level representation are non-overlapping cat egor-<br>
ies. Propositional attitudes as to paradigmatic cognitive states.1172 Are there non-<br>
propositional cognitive states?<br>
<br>
Consider non-propositional, amodal states. They differ from states in a sensory modal-<br>
ity subject to intermodal influence. (See note 18.) Recall that I take perceptual states, as a <br>
matter of terminology, to have a sensory modality (Chapter 2, the section Perceptual <br>
States as Sensory States). Nearly all perceptual states interact with perceptual <br>
states of other modalities. Visual perceptual states mutually influence tactile, auditory, and <br>
proprioceptive states.1173 Intermodal influence can be channeled to a perceptual state by <br>
representational states that are not themselves perceptual—attention commands, conative <br>
sets, memory, anticipation, affect, perceptual learning.1174 It can occur via non-<br>
representational mechanisms. Interaction among perceptual modalities is the norm.<br>
<br>
Amodality is a striking feature of a representational state. Some propositional states are <br>
amodal—including many expressed by language. Thoughts like recessions are burden-<br>
some for the poor and differentiation was discovered by Newton in the seventeenth cen-<br>
tury are amodal, even non-iconic. Some propositional states, such as visual perceptual <br><br>

<div id= 'FOOTNOTES'>
<b>FOOTNOTES</b><br>
<b>FN</b>1172 Recall that I use ‘concept’ to apply to ability-general representations that constitutively function to con-<br>
tribute to propositional structures. A concept in itself lacks propositional form. It functions constitutively to be a <br>
factor, a representational component, in a propositional state.<br>
<b>FN</b>1173 J. MacDonald and H. McGurk, ‘Visual Influences on Speech Perception Processes’, <i>Perception & <br>
Psychophysics</i> 24 (1978), 253–257; L. Shams, Y. Kamatani, and S. Shimojo, ‘Visual Illusion Induced by Sound’, <br>
<i>Cognitive Brain Research</i> 14 (2002), 147–152. The landmark paper on intermodal relations is M. Ernst and <br>
M. Banks, ‘Humans Integrate Visual and Haptic Information in a Statistically Optimal Fashion’, <i>Nature</i> 415 <br>
(2002), 429–433. See also Hillis, Ernst, Banks, and Landy, ‘Combining Sensory Information: Mandatory Fusion <br>
Within, but Not Between, Senses’. There is reason to think that these effects occur only at the perceptual level, <br>
among different perceptual modalities: K. Dieter, B. Hu, D. Knill, R. Blake, and D. Tadin, ‘Kinesthesis Can Make <br>
an Invisible Hand Visible’, <i>Psychological Science</i> 25 (2014), 66–75.<br>
<b>FN</b>1174 M. Ernst, ‘A Bayesian View on Multimodal Cue Integration’, in G. Knoblich, I. Thornton, M. Grosjean, and <br>
M. Shiffrar eds., <i>Human Body Perception From the Inside Out</i> (Oxford: Oxford University Press, 2006); J. Driver <br>
and T. Noesselt, ‘Multisensory Interplay Reveals Crossmodal Influences on ‘Sensory Specific’ Brain Regions, <br>
Neural Responses, and Judgments’, <i>Neuron</i> 57 (2008), 11–23; J. Navarra, A. Alsius, S. Soto-Faraco, and C. Spence, <br>
‘Assessing the Role of Attention in the Audio-Visual Integration of Speech’, <i>Information Fusion</i> 11 (2010), 4–11; <br>
P. Bruns, M. Maiworm, and B. Röder, ‘Reward Expectation Influences Audio-Visual Spatial Integration’, <i>Attention <br>
Perception and Psychophysics</i> 76 (2014), 1815–1827; R. Gau and U. Noppeney, ‘How Prior Expectations Shape <br>
Multisensory Perception’, <i>NeuroImage</i> 124 (2015), 876–886; and P. Bruns and B. Röder, ‘Sensory Calibration <br>
Integrates Information from the Immediate and the Cumulative Past’, <i>Scientific Reports</i> 5 (2015), 1–8. Of course, <br>
each of these perceptual-level capacities—perceptual-level attention commands, perceptual-level conative sets, <br>
perceptual-level memory, perceptual-level anticipation, perceptual-level affect, perceptual-level learning—can be <br>
“cognitively driven”. I think that computations that connect these abilities to produce intermodal effects on <br>
modal perceptual processing do not involve propositional attitudes. So “cognitively driven” cases are again non-<br>
revolutionary. They are accommodated within the computational perceptual-level, perceptual-motor system.</div>

