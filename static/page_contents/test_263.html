<div id="PGHEADER">
Egocentric Spatial Indexes in Perception 263</div>
<br><br>
thus referred to because they are not perceived. Only particulars with powers to cause the <br>
instantiation of perceptual states can be perceived. Spatial positions lack relevant causal <br>
powers. Spatial positions are computationally determined by operations that measure dis-<br>
tance and direction from the origin of the perceptual, spatial representational framework. <br>
Thus positions of perceived particulars are indicated canonically, as positions on a system-<br>
atic spatial grid. Positions are attributed by correlating a perceived (referred to) particular <br>
with a position in the spatial framework.<br>
<br>
LocL indicates a specific distance/direction relation between the spatial origin, referred <br>
to by an application of an egocentric index, and purportedly perceived particulars. <br>
Perceptual relational spatial attributives differ from attributives like Brown and Cubical. <br>
Color and shape-instances can cause sensory impressions. The color-instances and the <br>
cubical-shape-instances can, literally, be seen. We do not perceive instances of spatial rela-<br>
tions, such as specific distances. (See Chapter 6, the section Perceptual Attribution <br>
of Relations.). We perceptually attribute them.<br>
<br>
So I do not equip LocL with a sign for a referential application that would function to <br>
betoken the relational attribute-instance. LocL indicates a relation within the spatial <br>
framework. It is not attributed to instances of the relation. Any such instances are not <br>
perceptually referred to. The attributive relates a purportedly perceived body to the <br>
indexed position of the perceiver.<br>
<br>
A sample representational content with visual-perception mode is as follows:<br><br>
(here-cego x1)(that x2)[that (x3)(that x4)<br>
<br>
(brownr1(c)(x2), brownr1(i)(x3), cubicalb1(c)(x2), cubicalb1(i)(x4), LocL(c)(x2 , x1), bodyd1(i)(x2))]<i>.<br><br>
</i>This formula reads roughly: that brown cubical body x2 at location <i>L</i> relative to here-<br>
cego x1. The reading is rough because it omits the <i>de re</i> references to instances of <i>brown</i> and <br>
<i>cubical</i>. I omit temporal representation.<br>
<br>
The perceptually attributed location, <i>L</i>, of the body is measured by a combination of <br>
capacities for determining direction and distance. These are standing capacities to indicate <br>
canonically and metrically, within an ability-general spatial representational system, a <br>
specific location relative to the origin. L and comparable specifications are structurally <br>
relevant parts of Loc attributives. In perceptual representation, they never occur outside a <br>
framework that indicates other locations. So LocL is a fragment of a map-like framework <br>
for computing positions.<br>
<br>
There are multiple spatial frameworks at different scales, even within a given perceptual <br>
system. So the single egocentrically anchored spatial framework is an oversimplification.<br>
<br>
Another issue that I have elided is the occurrence in vision of spatial frameworks that <br>
are object-centered. Although few scientists think that vision uses object-centered (or any <br>
other allocentric) maps that are not coordinated with a basic egocentric framework, many, <br>
probably most, believe that there are object-centered as well as egocentric frameworks.251 <br>
A framework for determining the natural top and bottom of a body, like a tree, and a <br><br>

<div id= 'FOOTNOTES'>
<b>FOOTNOTES</b><br>
<b>Cont FN</b>251 F. Filimon, ‘Are All Spatial Reference Frames Egocentric? Reinterpreting Evidence for Allocentric, Object-<br>
Centered, or World-Centered Reference Frames’, <i>Frontiers of Human Neuroscience</i> 9 (2015), 1–21; Erdogan and <br>
Jacobs, ‘Visual Shape Perception as Bayesian Inference of 3D Object-Centered Shape Representations’.</div>

